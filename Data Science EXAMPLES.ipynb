{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture 8.3 exercise (comparing groups):\n",
    "\n",
    "    We are given datasets\n",
    "        x = [4.3, 5.1, 6.1, 6.8, 7.4, 8.8, 9.9]\n",
    "        y = [8.3, 8.5, 8.9]\n",
    "    Test whether the two groups have the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1652"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Vague hypotheses:\n",
    "#    (TAKE H0 TO BE DESCRIBED SCENARIO: groups the same)\n",
    "#    H0: distributions are the same\n",
    "#    H1: distributions are not the same (go by observed data)\n",
    "\n",
    "# 2. Test statistic: data point->test result\n",
    "#    In this case, let's use difference in means between (x, y).\n",
    "def t(x, y): return np.abs(np.mean(y) - np.mean(x))\n",
    "\n",
    "# 3. Data point format:\n",
    "#    For our test stat to make sense, data point must be (x, y).\n",
    "#    Question gives us one data point.\n",
    "x = [4.3, 5.1, 6.1, 6.8, 7.4, 8.8, 9.9]\n",
    "y = [8.3, 8.5, 8.9]\n",
    "\n",
    "# 4. Test result in H1:\n",
    "#    In this case, the only data we have to represent H1 is the observed stuff.\n",
    "#    So take the observed t.\n",
    "#    If we were being pedantic, could resample data first then take average t, to avoid e.g. t=0. \n",
    "t_h1 = t(x, y)\n",
    "\n",
    "# 5. Refine H1 hypothesis:\n",
    "#    H1: test stat >= t_h1 (as we're looking for more difference)\n",
    "\n",
    "# 6. Sampling distribution:\n",
    "#    Define test distribution extending H0.\n",
    "#    In this case, best we know of is empirical.\n",
    "#    ! This requires a sample of H0 !:\n",
    "def h0_xy_random():\n",
    "    xy = np.concatenate([x, y])\n",
    "    return (np.random.choice(xy, size=len(x)),\n",
    "            np.random.choice(xy, size=len(y)))\n",
    "s_h0 = [h0_xy_random() for _ in range(10000)]\n",
    "ts_h0 = [t(*xy) for xy in s_h0]\n",
    "# Now use empirical distribution to define p functions\n",
    "def p_lesser(t_result): return np.mean(ts_h0 <= t_result)\n",
    "def p_greater(t_result): return np.mean(ts_h0 >= t_result)\n",
    "def p_1t(t_result): return np.min([p_lesser(t_result), p_greater(t_result)])\n",
    "def p_2t(t_result): return 2 * p_1t(t_result)\n",
    "\n",
    "# 7. P-value:\n",
    "#    Find chance of getting H1 in our H0 sampling distribution.\n",
    "#    i.e. chance that true mean is less than observed.\n",
    "p_h1 = p_1t(t_h1)\n",
    "\n",
    "# 8. Conclusion:\n",
    "p_h1\n",
    "# If this is <0.05, then reject H1 and accept H0: they are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mock exam paper 3 (https://www.cl.cam.ac.uk/teaching/2021/DataSci/ex/exam3.pdf):"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a)\n",
    "   θ_hat = nA / 500\n",
    "   = 0.52 in this case\n",
    "   \n",
    "b)\n",
    "    A range of values which we are 95% sure θ_hat could fall in given\n",
    "    the observed data and n value. i.e. to be more technical, an\n",
    "    interval on the sampling distribution for θ which has area 0.95,\n",
    "    centred around the mean.\n",
    "    \n",
    "    I believe a two-sided interval is more appropriate, as the true\n",
    "    effectiveness of algorithm A could be either greater or lesser\n",
    "    than observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.476, 0.564)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data point: nA\n",
    "observed_nA = 260\n",
    "\n",
    "# Test Statistic: data point -> test result\n",
    "#                 nA -> theta hat\n",
    "def t(nA):\n",
    "    return nA/500\n",
    "\n",
    "# Sample: generate sample of nA's by resampling binomial\n",
    "s = np.random.binomial(n=500, p=0.52, size=10000)\n",
    "\n",
    "# Sampling distribution: empirical; generated from sample\n",
    "ts = [t(nA) for nA in s]\n",
    "\n",
    "# Find confidence interval from sampling distribution\n",
    "lo,hi = np.quantile(ts, [0.025, 0.975])\n",
    "\n",
    "(lo, hi)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c)\n",
    "\n",
    "    We  set H0 = \"theta is a 1/2\", H1= \"theta is not 1/2\", generate a synthetic dataset under this assumption, then find the p-value for our observed theta_hat of 0.52 within its empirical distribution.\n",
    "\n",
    "    P-value is the probability of observing a result \"at least as extreme\" as a particular test result in some distribution. For example, if H0=\"theta is 1/2\", a low p-value indicates a low chance of H1 (\"theta is not 1/2\") being true, hence a higher chance of H0. e.g. we might accept H0 for p<0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.403"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Vague hypotheses:\n",
    "#    H0: theta=1/2\n",
    "#    H1: theta!=1/2 (we observed 0.52)\n",
    "\n",
    "# 2. Test statistic: data point->test result\n",
    "#    In this case, we're testing theta.\n",
    "def t(nA, n): return nA/n\n",
    "\n",
    "# 3. Data point format:\n",
    "#    For our test stat to make sense, data point must be (nA, n).\n",
    "\n",
    "# 4. Test result in H1:\n",
    "#    In this case, we already have it - 0.52\n",
    "t_h1 = 0.52\n",
    "\n",
    "# 5. Refine H1 hypothesis:\n",
    "#    H1: test stat at least as extreme as 0.52\n",
    "\n",
    "# 6. Sampling distribution:\n",
    "#    Define test distribution extending H0.\n",
    "#    -> We could use a binomial sampling distribution (as t is\n",
    "#       proportional to nA which is binomial), but lecturer seems\n",
    "#       to want us to just use empirical :/ ?\n",
    "ts_h0 = [t(nA, 500) for nA in np.random.binomial(n=500, p=0.5, size=10000)]\n",
    "# Now use empirical distribution to define p functions\n",
    "def p_lesser(t_result): return np.mean(ts_h0 <= np.float64(t_result))\n",
    "def p_greater(t_result): return np.mean(ts_h0 >= np.float64(t_result))\n",
    "def p_1t(t_result): return np.min([p_lesser(t_result), p_greater(t_result)])\n",
    "def p_2t(t_result): return 2 * p_1t(t_result)\n",
    "\n",
    "# 7. P-value:\n",
    "#    Find chance of getting H1 in our H0 sampling distribution.\n",
    "#    Perform a TWO-TAILED test because H0 could be disproved in any direction.\n",
    "p_h1 = p_2t(t_h1)\n",
    "\n",
    "# 8. Conclusion:\n",
    "p_h1\n",
    "# If this is <0.05, then reject H1 and accept H0: theta is 1/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3946"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empirical sampling distribution in H0 synthesized dataset\n",
    "ts = [t(nA) for nA in np.random.binomial(n=500, p=0.5, size=10000)]\n",
    "\n",
    "# P-value via two-tail test\n",
    "def p_lt(ts, val): return np.mean(ts <= np.float64(val))\n",
    "def p_gt(ts, val): return np.mean(ts >= np.float64(val))\n",
    "p = 2 * np.min([p_lt(ts, 0.52), p_gt(ts, 0.52)])\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
